{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# EDA with pandas-profiling\n",
    "import ydata_profiling as pdp\n",
    "\n",
    "# Miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"titanic/train.csv\")\n",
    "\n",
    "# # Generate a profiling report\n",
    "# profile = pdp.ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "# profile.to_file(\"pandas_profiling_report.html\")  # Save report as HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"titanic/train.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "df = df.drop(columns=['PassengerId', \n",
    "                      'Ticket',  \n",
    "                      'Cabin'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Missing Count  Missing Percentage\n",
      "Age                 177           19.865320\n",
      "Embarked              2            0.224467\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of missing values in each column\n",
    "missing_count = df.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Combine the count and percentage into a DataFrame\n",
    "df_missing = pd.DataFrame({\n",
    "    'Missing Count': missing_count,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "# Filter the DataFrame to include only columns with missing percentage greater than 0\n",
    "df_missing = df_missing[df_missing['Missing Percentage'] > 0]\n",
    "\n",
    "# Optionally, sort the DataFrame by the number of missing values (descending order)\n",
    "df_missing = df_missing.sort_values(by='Missing Count', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_missing)\n",
    "\n",
    "\n",
    "# Fill missing values in 'Embarked' with the most frequent value\n",
    "most_frequent_embarked = df['Embarked'].mode()[0]\n",
    "df['Embarked'].fillna(most_frequent_embarked, inplace=True)\n",
    "\n",
    "# Fill missing values in 'Age' with the median value\n",
    "median_age = df['Age'].median()\n",
    "df['Age'].fillna(median_age, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of numeric columns:\n",
      "     Column  Skewness\n",
      "5      Fare  4.787317\n",
      "3     SibSp  3.695352\n",
      "4     Parch  2.749117\n",
      "2       Age  0.510245\n",
      "0  Survived  0.478523\n",
      "1    Pclass -0.630548\n",
      "\n",
      "New skewness after capping:\n",
      "Fare     1.717339\n",
      "SibSp    1.938712\n",
      "Parch    1.679480\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric columns from the DataFrame\n",
    "numeric_columns = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate the skewness for each numeric column in the DataFrame\n",
    "skewness_values = numeric_columns.skew()\n",
    "\n",
    "# Create a DataFrame to store the skewness values\n",
    "df_skew = pd.DataFrame({\n",
    "    'Column': skewness_values.index,\n",
    "    'Skewness': skewness_values.values\n",
    "})\n",
    "\n",
    "# Optionally, sort the DataFrame by skewness in descending order\n",
    "df_skew = df_skew.sort_values(by='Skewness', ascending=False)\n",
    "\n",
    "# Display the DataFrame with skewness values\n",
    "print(\"Skewness of numeric columns:\")\n",
    "print(df_skew)\n",
    "\n",
    "# Define columns for which to apply capping based on high skewness\n",
    "columns_to_cap = df_skew[df_skew['Skewness'] > 1]['Column']\n",
    "\n",
    "# Apply upper capping at the 95th percentile for columns with high skewness\n",
    "for col in columns_to_cap:\n",
    "    upper_cap = df[col].quantile(0.95)  # Calculate the 95th percentile\n",
    "    df[col] = np.where(df[col] > upper_cap, upper_cap, df[col])  # Cap values above the 95th percentile\n",
    "\n",
    "# Display the new skewness values after capping\n",
    "print(\"\\nNew skewness after capping:\")\n",
    "print(df[columns_to_cap].skew())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [Survived, Pclass, Name, Sex, Age, SibSp, Parch, Fare, Embarked]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "# Display the duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a comprehensive regex pattern to search for a variety of titles\n",
    "title_pattern = r'\\b(Dr|Prof|Ph\\.D\\.|M\\.Sc\\.|B\\.Sc\\.|M\\.A\\.|B\\.A\\.|MBA|MD|DDS|DVM|JD|LLD|Sir|Dame|Lord|Lady|Baron|Baroness|Rev\\.|Father|Sister|Capt|Col|Major|Lt|Sgt|Admiral|General|Eng\\.|Architect|Attorney)\\b'\n",
    "\n",
    "# Apply the pattern to the Name column to extract titles\n",
    "df['Academic Title'] = df['Name'].apply(lambda x: re.search(title_pattern, x))\n",
    "\n",
    "# Create a new column 'Title' where 1 indicates the presence of a title and 0 indicates no title\n",
    "df['Title'] = df['Academic Title'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "# Drop the temporary 'Academic Title' column if it's no longer needed\n",
    "df = df.drop(columns=['Academic Title', 'Name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Variables:\n",
      "Index(['Pclass', 'Sex', 'Embarked'], dtype='object')\n",
      "   Survived  Sex   Age  SibSp  Parch     Fare  Title  Pclass_1  Pclass_2  \\\n",
      "0         0    1  22.0    1.0    0.0   7.2500      0         0         0   \n",
      "1         1    0  38.0    1.0    0.0  71.2833      0         1         0   \n",
      "2         1    0  26.0    0.0    0.0   7.9250      0         0         0   \n",
      "3         1    0  35.0    1.0    0.0  53.1000      0         1         0   \n",
      "4         0    1  35.0    0.0    0.0   8.0500      0         0         0   \n",
      "\n",
      "   Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0         1           0           0           1  \n",
      "1         0           1           0           0  \n",
      "2         1           0           0           1  \n",
      "3         0           0           0           1  \n",
      "4         1           0           0           1  \n"
     ]
    }
   ],
   "source": [
    "# Select only categorical columns from the DataFrame\n",
    "df['Pclass'] = df['Pclass'].astype('category')\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Display the names of all categorical columns\n",
    "print(\"Categorical Variables:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "# Label encode the 'Sex' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "\n",
    "# One-hot encode the 'Pclass' and 'Embarked' columns\n",
    "df = pd.get_dummies(df, columns=['Pclass', 'Embarked'], drop_first=False)\n",
    "\n",
    "\n",
    "# Step 1: Convert all boolean columns to integers (0 and 1)\n",
    "df = df.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
    "\n",
    "# Step 2: Ensure all columns are numeric\n",
    "df = df.apply(pd.to_numeric)\n",
    "# Display the first few rows to verify the transformations\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
